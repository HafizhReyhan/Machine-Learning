{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Impor Pustaka ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# Prapemrosesan dan Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Model Clustering\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Metrik Evaluasi\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, silhouette_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline:\n",
    "    \"\"\"Mengelola alur kerja pembersihan data dan feature engineering.\"\"\"\n",
    "    def __init__(self, file_path, sample_size=10000, random_state=42):\n",
    "        self.file_path = file_path\n",
    "        self.sample_size = sample_size\n",
    "        self.random_state = random_state\n",
    "        self.scaler = StandardScaler()\n",
    "        self.tfidf = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "\n",
    "    def _load_and_clean(self):\n",
    "        \"\"\"Memuat, membersihkan, dan memvalidasi data transaksi.\"\"\"\n",
    "        data = pd.read_csv(self.file_path, encoding='ISO-8859-1')\n",
    "        data.dropna(subset=['CustomerID'], inplace=True)\n",
    "        data['Description'].fillna('Unknown', inplace=True)\n",
    "        data = data[(data['Quantity'] > 0) & (data['UnitPrice'] > 0)]\n",
    "        data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'], format='%m/%d/%Y %H:%M')\n",
    "        data.drop_duplicates(inplace=True)\n",
    "        return data\n",
    "\n",
    "    def _engineer_features(self, data):\n",
    "        \"\"\"Menciptakan fitur baru dan mengubah fitur yang ada.\"\"\"\n",
    "        data_fe = data.copy()\n",
    "        data_fe['DayOfWeek'] = data_fe['InvoiceDate'].dt.dayofweek\n",
    "        data_fe['Hour'] = data_fe['InvoiceDate'].dt.hour\n",
    "        data_fe[['Quantity_scaled', 'UnitPrice_scaled']] = self.scaler.fit_transform(data_fe[['Quantity', 'UnitPrice']])\n",
    "\n",
    "        # Sampling untuk efisiensi komputasi\n",
    "        data_sample = data_fe.sample(n=self.sample_size, random_state=self.random_state)\n",
    "        \n",
    "        # TF-IDF pada deskripsi produk\n",
    "        description_tfidf = self.tfidf.fit_transform(data_sample['Description'])\n",
    "        tfidf_df = pd.DataFrame(description_tfidf.toarray(), columns=self.tfidf.get_feature_names_out(), index=data_sample.index)\n",
    "\n",
    "        # Gabungkan semua fitur menjadi dataset final untuk clustering\n",
    "        features_to_cluster = ['Quantity_scaled', 'UnitPrice_scaled', 'DayOfWeek', 'Hour']\n",
    "        final_data_for_clustering = data_sample[features_to_cluster].join(tfidf_df)\n",
    "        \n",
    "        return data_sample, final_data_for_clustering\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Menjalankan seluruh pipeline prapemrosesan.\"\"\"\n",
    "        print(\"Tahap 1: Memuat dan membersihkan data...\")\n",
    "        cleaned_data = self._load_and_clean()\n",
    "        print(f\"   -> Data bersih berisi {len(cleaned_data)} baris.\")\n",
    "\n",
    "        print(f\"Tahap 2: Melakukan feature engineering pada sampel {self.sample_size} data...\")\n",
    "        self.original_sample, self.final_data_for_clustering = self._engineer_features(cleaned_data)\n",
    "        print(\"   -> Pipeline data selesai. Data siap untuk di-cluster.\")\n",
    "\n",
    "        return self.final_data_for_clustering, self.original_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterAnalyzer:\n",
    "    \"\"\"Menganalisis dan memvisualisasikan hasil dari berbagai model clustering.\"\"\"\n",
    "    def __init__(self, data_for_clustering, original_sample_data):\n",
    "        self.X = data_for_clustering.values\n",
    "        self.original_data = original_sample_data\n",
    "        self.models = self._define_models()\n",
    "        self.results_df = pd.DataFrame()\n",
    "        self.labels_dict = {}\n",
    "        \n",
    "        # Lakukan PCA sekali untuk efisiensi\n",
    "        print(\"Tahap 3: Melakukan reduksi dimensi PCA untuk visualisasi...\")\n",
    "        self.pca = PCA(n_components=2, random_state=42)\n",
    "        self.X_pca = self.pca.fit_transform(self.X)\n",
    "\n",
    "    def _define_models(self):\n",
    "        \"\"\"Mendefinisikan model-model clustering yang akan diuji.\"\"\"\n",
    "        return {\n",
    "            'KMeans': KMeans(n_clusters=5, random_state=42, n_init=10),\n",
    "            'Agglomerative': AgglomerativeClustering(n_clusters=5),\n",
    "            'Spectral': SpectralClustering(n_clusters=5, random_state=42, affinity='nearest_neighbors'),\n",
    "            'GaussianMixture': GaussianMixture(n_components=5, random_state=42)\n",
    "        }\n",
    "\n",
    "    def run_and_evaluate(self):\n",
    "        \"\"\"Menjalankan semua model dan menghitung metrik evaluasi.\"\"\"\n",
    "        print(\"Tahap 4: Menjalankan dan mengevaluasi model clustering...\")\n",
    "        results = []\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"   - Fitting {name}...\")\n",
    "            labels = model.fit_predict(self.X)\n",
    "            self.labels_dict[name] = labels\n",
    "            \n",
    "            results.append({\n",
    "                'Model': name,\n",
    "                'Silhouette Score': silhouette_score(self.X, labels),\n",
    "                'Davies-Bouldin Index': davies_bouldin_score(self.X, labels),\n",
    "                'Calinski-Harabasz Score': calinski_harabasz_score(self.X, labels),\n",
    "            })\n",
    "        self.results_df = pd.DataFrame(results).sort_values('Silhouette Score', ascending=False)\n",
    "        return self.results_df\n",
    "\n",
    "    def visualize_all(self, best_model_name):\n",
    "        \"\"\"Menjalankan semua fungsi visualisasi.\"\"\"\n",
    "        print(\"\\nTahap 5: Membuat visualisasi perbandingan dan analisis...\")\n",
    "        self._plot_metrics_comparison()\n",
    "        self._plot_pca_clusters()\n",
    "        self._plot_cluster_profiles(best_model_name)\n",
    "        self._plot_dendrogram()\n",
    "\n",
    "    def _plot_metrics_comparison(self):\n",
    "        \"\"\"Membuat bar plot perbandingan metrik.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(22, 6))\n",
    "        metrics = ['Silhouette Score', 'Davies-Bouldin Index', 'Calinski-Harabasz Score']\n",
    "        pal = \"viridis\"\n",
    "        for i, metric in enumerate(metrics):\n",
    "            sns.barplot(x=metric, y='Model', data=self.results_df.sort_values(metric), ax=axes[i], palette=pal)\n",
    "            axes[i].set_title(f'Perbandingan {metric}', fontsize=14)\n",
    "            axes[i].set_xlabel('Skor')\n",
    "        plt.suptitle('Perbandingan Metrik Evaluasi Clustering', fontsize=18)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "        \n",
    "    def _plot_pca_clusters(self):\n",
    "        \"\"\"Membuat scatter plot PCA untuk setiap model.\"\"\"\n",
    "        num_models = len(self.models)\n",
    "        fig, axes = plt.subplots(1, num_models, figsize=(8 * num_models, 6), sharey=True, sharex=True)\n",
    "        for i, (name, model) in enumerate(self.models.items()):\n",
    "            labels = self.labels_dict[name]\n",
    "            sns.scatterplot(x=self.X_pca[:, 0], y=self.X_pca[:, 1], hue=labels, palette='viridis', s=30, ax=axes[i], legend='full', alpha=0.7)\n",
    "            axes[i].set_title(f'Cluster PCA - {name}', fontsize=14)\n",
    "            axes[i].set_xlabel('Komponen PCA 1')\n",
    "        axes[0].set_ylabel('Komponen PCA 2')\n",
    "        plt.suptitle('Visualisasi Cluster dengan Reduksi Dimensi PCA', fontsize=18)\n",
    "        plt.show()\n",
    "\n",
    "    def _plot_cluster_profiles(self, best_model_name):\n",
    "        \"\"\"Membuat boxplot untuk analisis profil kluster.\"\"\"\n",
    "        print(f\"\\nAnalisis Profil Cluster dari Model Terbaik: {best_model_name}\")\n",
    "        profile_data = self.original_data.copy()\n",
    "        profile_data['Cluster'] = self.labels_dict[best_model_name]\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "        profile_features = ['Quantity', 'UnitPrice', 'DayOfWeek', 'Hour']\n",
    "        titles = ['Distribusi Kuantitas', 'Distribusi Harga Satuan', 'Distribusi Hari Pembelian', 'Distribusi Jam Pembelian']\n",
    "        \n",
    "        for i, feature in enumerate(profile_features):\n",
    "            ax = axes[i//2, i%2]\n",
    "            sns.boxenplot(x='Cluster', y=feature, data=profile_data, ax=ax, palette='viridis')\n",
    "            ax.set_title(titles[i], fontsize=14)\n",
    "            if feature in ['Quantity', 'UnitPrice']:\n",
    "                ax.set_yscale('log') # Skala log untuk menangani outlier\n",
    "                \n",
    "        plt.suptitle(f'Profil Karakteristik Cluster (Model: {best_model_name})', fontsize=18)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "        \n",
    "    def _plot_dendrogram(self):\n",
    "        \"\"\"Membuat dendrogram dari data yang telah disample lebih kecil.\"\"\"\n",
    "        print(\"\\nMembuat Dendrogram untuk Hierarchical Clustering (menggunakan 500 sampel)...\")\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        dendrogram_data = self.X[:500] # Sample kecil untuk dendrogram\n",
    "        linked = linkage(dendrogram_data, method='ward')\n",
    "        dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True)\n",
    "        plt.title('Dendrogram Hierarchical Clustering', fontsize=16)\n",
    "        plt.xlabel('Indeks Sampel', fontsize=12)\n",
    "        plt.ylabel('Jarak', fontsize=12)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Jalankan Pipeline Data ---\n",
    "pipeline = DataPipeline(file_path='UTSClustering.csv', sample_size=10000)\n",
    "data_to_cluster, original_sample = pipeline.run()\n",
    "\n",
    "# --- 2. Jalankan Analisis Clustering ---\n",
    "analyzer = ClusterAnalyzer(data_to_cluster, original_sample)\n",
    "results_df = analyzer.run_and_evaluate()\n",
    "\n",
    "# --- 3. Tampilkan Hasil Evaluasi Numerik ---\n",
    "print(\"\\n--- Hasil Evaluasi Performa Model ---\")\n",
    "display(results_df)\n",
    "\n",
    "# --- 4. Jalankan Semua Visualisasi ---\n",
    "# Berdasarkan hasil, Agglomerative Clustering adalah kandidat kuat sebagai model terbaik\n",
    "best_model_for_profiling = 'Agglomerative' \n",
    "analyzer.visualize_all(best_model_name=best_model_for_profiling)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
